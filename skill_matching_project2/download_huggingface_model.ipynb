{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5959f9c4-3a41-4018-b0bb-9047093c6092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/ishanporwal/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/ishanporwal/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/ishanporwal/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ishanporwal/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/ishanporwal/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ishanporwal/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21337f07-71c6-4b3a-a871-d3c4c2f4923a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "211d0ab2-6285-44de-a34c-1a3e02681872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting download_huggingface_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile download_huggingface_model.py\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# download pretrained\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# save to local directory\n",
    "model.save('./model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f68800a6-e5e4-4174-8173-1a06b34eadc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting create_embeddings.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile create_embeddings.py\n",
    "\n",
    "\n",
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "skill_list_file = r'./master_skills_list.txt' # skill names from ChatGPT\n",
    "skill_emb_file = r'./master_emb_list.pkl' # output file\n",
    "model_path = r'./model' # the path to the downloaded model\n",
    "\n",
    "# use the model we downloaded in the model directory\n",
    "model = SentenceTransformer(model_path)\n",
    "\n",
    "# read in the skill names\n",
    "with open(skill_list_file, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    master_skills_list = []\n",
    "    for l in lines:\n",
    "        master_skills_list.append(l.replace(\"\\n\", \"\"))\n",
    "\n",
    "# create the embeddings and write it as a pickle file\n",
    "master_skill_embs = model.encode(master_skills_list)\n",
    "with open(skill_emb_file, 'wb') as f:\n",
    "    pickle.dump(master_skill_embs, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b2df657-6e00-4fae-9785-9bc69cc88a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting recommend_without_cloudrun.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile recommend_without_cloudrun.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pypdf\n",
    "import pickle\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "import werkzeug\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Use a pre-trained model from Hugging Face\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Check if a GPU is available and set the device accordingly\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "embedder.to(device)\n",
    "\n",
    "def read_pdf_text(pdf_path):\n",
    "    '''\n",
    "    Parses a PDF file and returns the contents.\n",
    "    '''\n",
    "    file_text = ''\n",
    "    with open(pdf_path, 'rb') as f:\n",
    "        pdf = pypdf.PdfReader(f)\n",
    "        for page in range(len(pdf.pages)):\n",
    "            file_text += (pdf.pages[page].extract_text())\n",
    "    return file_text\n",
    "\n",
    "\n",
    "def cut_and_clean(string):\n",
    "    '''\n",
    "    Cut up text into smaller pieces for the model to read and clean the pieces.\n",
    "    '''\n",
    "    chunks = re.split(r'\\n|\\.', string)\n",
    "    chunks = [x for x in chunks if len(x) > 4]\n",
    "    c_chunks = list()\n",
    "    for i in chunks:\n",
    "        i = ''.join((x for x in i if not x.isdigit()))  # throw away digits\n",
    "        i = re.sub(r'[^a-zA-Z0-9 \\n\\.,]', ' ', i)  # throw away special characters\n",
    "        i = \" \".join(i.split())  # remove extra spaces\n",
    "        i = i.lower()  # lowercase\n",
    "        if len(i.split()) > 3:\n",
    "            c_chunks.append(i)\n",
    "    return c_chunks\n",
    "\n",
    "\n",
    "def match_snippets(snippets, master_phrase_embs, master_phrase_list, top_k):\n",
    "    '''\n",
    "    Match a list of short phrases to a set of phrase embeddings.\n",
    "    '''\n",
    "    skill_recommendation = pd.DataFrame()\n",
    "    for query in snippets:\n",
    "        query_embedding = embedder.encode(query.strip(), convert_to_tensor=True, device=device)\n",
    "        cos_scores = util.cos_sim(query_embedding, master_phrase_embs)[0]\n",
    "        top_results = torch.topk(cos_scores, k=top_k)\n",
    "\n",
    "        skills_list = list()\n",
    "        score_list = list()\n",
    "        for score, idx in zip(top_results.values.cpu().numpy(), top_results.indices.cpu().numpy()):\n",
    "            skills_list.append(master_phrase_list[idx])\n",
    "            score_list.append(score.item())\n",
    "        \n",
    "        skills_df = pd.DataFrame(skills_list)\n",
    "        score_df = pd.DataFrame(score_list)\n",
    "        sk_sc_df = pd.concat([skills_df, score_df], axis=1)\n",
    "        sk_sc_df.columns = ['Phrase', 'Score']\n",
    "        skill_recommendation = pd.concat([skill_recommendation, sk_sc_df]).reset_index(drop=True)\n",
    "    \n",
    "    return skill_recommendation\n",
    "\n",
    "\n",
    "\n",
    "def main(input_file, master_skills_emb_binary, master_skills_list, top_k):\n",
    "\n",
    "    '''\n",
    "    Save a set of suggestions for skills from a CV.\n",
    "    '''\n",
    "    with open(master_skills_emb_binary, 'rb') as f:\n",
    "        master_phrase_embs = pickle.load(f)\n",
    "    \n",
    "    # Convert numpy array to PyTorch tensor and move to the appropriate device\n",
    "    master_phrase_embs = torch.tensor(master_phrase_embs).to(device)\n",
    "    \n",
    "    with open(master_skills_list, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        master_phrase_list = [l.replace(\"\\n\", \"\") for l in lines]\n",
    "    \n",
    "    file_text = read_pdf_text(input_file)\n",
    "    cv_snippets = cut_and_clean(file_text)\n",
    "    skill_recommendation = match_snippets(cv_snippets, master_phrase_embs, master_phrase_list, top_k=top_k)\n",
    "    skill_recommendation = skill_recommendation[skill_recommendation['Score'] >= 0.5]\n",
    "    skill_recommendation = skill_recommendation.sort_values('Score', ascending=False)\n",
    "    skill_recommendation = skill_recommendation.drop_duplicates(subset='Phrase').reset_index(drop=True)\n",
    "    skill_recommendation = skill_recommendation.rename(columns={'Phrase': 'Skill'})\n",
    "    skill_recommendation.to_csv(os.path.splitext(input_file)[0] + '_skill_suggestions.csv', index=False)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if 'ipykernel_launcher.py' in sys.argv[0]:\n",
    "        sys.argv = [arg for arg in sys.argv if not arg.endswith('.json')]\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--input_file')\n",
    "    parser.add_argument('--master_skills_emb_binary', required=False, default=r'./master_emb_list.pkl')\n",
    "    parser.add_argument('--master_skills_list', required=False, default=r'./master_skills_list.txt')\n",
    "    parser.add_argument('--top_k', required=False, default=5, type=int)  # Ensure top_k is parsed as an integer\n",
    "    args = parser.parse_args()\n",
    "    main(input_file=args.input_file, master_skills_emb_binary=args.master_skills_emb_binary, master_skills_list=args.master_skills_list, top_k=args.top_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcbe2641-dfc8-4f3c-8db2-3bfea15f955c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main.py\n",
    "\n",
    "import pandas as pd\n",
    "import pypdf\n",
    "import pickle\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "from flask import Flask, request, json, Response\n",
    "from flask_restx import Api, Resource, fields, abort\n",
    "import werkzeug\n",
    "import numpy as np\n",
    "\n",
    "app = Flask(__name__)\n",
    "api = Api(app)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "file_upload_parser = api.parser()\n",
    "file_upload_parser.add_argument('file', location='files', type=werkzeug.datastructures.FileStorage, required=True)\n",
    "\n",
    "embedder = SentenceTransformer('paraphrase-MiniLM-L6-v2').to(device)  # Ensure you are using the same model\n",
    "\n",
    "def read_pdf_text(file_path):\n",
    "    pdf_reader = pypdf.PdfReader(file_path)\n",
    "    text = ''\n",
    "    for page in pdf_reader.pages:\n",
    "        text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "def cut_and_clean(text):\n",
    "    # Assuming that the cut_and_clean function splits text into snippets and cleans them\n",
    "    snippets = re.split(r'\\n+', text)\n",
    "    snippets = [snippet.strip() for snippet in snippets if snippet.strip()]\n",
    "    return snippets\n",
    "\n",
    "def match_snippets(snippets, master_phrase_embs, master_phrase_list, top_k=5):\n",
    "    # Embed snippets\n",
    "    snippet_embs = embedder.encode(snippets, convert_to_tensor=True, device=device)\n",
    "\n",
    "    # Print shapes for debugging\n",
    "    print(f\"Shape of snippet_embs: {snippet_embs.shape}\")\n",
    "    print(f\"Shape of master_phrase_embs: {master_phrase_embs.shape}\")\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    cos_scores = util.pytorch_cos_sim(snippet_embs, master_phrase_embs)\n",
    "    \n",
    "    # Ensure top_k is correctly set\n",
    "    top_k = min(top_k, len(master_phrase_list))  # Limit top_k to the number of available skills\n",
    "    \n",
    "    top_results = torch.topk(cos_scores, k=top_k, dim=1)\n",
    "\n",
    "    recommendations = []\n",
    "    for idx, snippet in enumerate(snippets):\n",
    "        for score, idx in zip(top_results.values.cpu().numpy()[idx], top_results.indices.cpu().numpy()[idx]):\n",
    "            recommendations.append({'Snippet': snippet, 'Phrase': master_phrase_list[idx], 'Score': score})\n",
    "    \n",
    "    # Print recommendations for debugging\n",
    "    print(f\"Recommendations: {recommendations}\")\n",
    "\n",
    "    return pd.DataFrame(recommendations)\n",
    "\n",
    "@api.route('/skills_from_cv')\n",
    "class SkillsFromCV(Resource):\n",
    "    @api.expect(file_upload_parser)\n",
    "    def post(self, top_k=5):\n",
    "        args = file_upload_parser.parse_args()\n",
    "        input_file = args['file']\n",
    "        input_file.save('file.pdf')\n",
    "\n",
    "        master_skills_emb_binary = r'./master_emb_list.pkl'\n",
    "        master_skills_list = r'./master_skills_list.txt'\n",
    "\n",
    "        with open(master_skills_emb_binary, 'rb') as f:\n",
    "            master_phrase_embs = pickle.load(f)\n",
    "        with open(master_skills_list, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            master_phrase_list = [l.replace(\"\\n\", \"\") for l in lines]\n",
    "\n",
    "        # Convert numpy array to PyTorch tensor and move to the appropriate device\n",
    "        master_phrase_embs = torch.tensor(master_phrase_embs).to(device)\n",
    "\n",
    "        file_text = read_pdf_text('file.pdf')\n",
    "        cv_snippets = cut_and_clean(file_text)\n",
    "        skill_recommendation = match_snippets(cv_snippets, master_phrase_embs, master_phrase_list, top_k=top_k)\n",
    "\n",
    "        # Additional debug prints\n",
    "        print(f\"Skill recommendation before filtering: {skill_recommendation}\")\n",
    "\n",
    "        skill_recommendation = skill_recommendation[skill_recommendation['Score'] >= 0.3]\n",
    "        skill_recommendation = skill_recommendation.sort_values('Score', ascending=False)\n",
    "        skill_recommendation = skill_recommendation.drop_duplicates(subset='Phrase').reset_index(drop=True)\n",
    "        skill_recommendation = skill_recommendation.rename(columns={'Phrase': 'Skill'})\n",
    "        skill_recommendation = skill_recommendation.replace({np.nan: None})\n",
    "\n",
    "        # Additional debug prints\n",
    "        print(f\"Skill recommendation after filtering: {skill_recommendation}\")\n",
    "\n",
    "        response = {'recommendations': skill_recommendation.to_dict(orient='records')}\n",
    "        return response\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, host='0.0.0.0', port=8080)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
